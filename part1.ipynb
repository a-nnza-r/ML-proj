{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFileEmissionParameters(filepath):\n",
    "    y_count = {}\n",
    "    emission_count = {}\n",
    "    training_observations_x = []\n",
    "    with open(filepath, 'r',encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            line = line.strip()\n",
    "            last_space_idx = line.rfind(\" \")\n",
    "            x, y = line[:last_space_idx], line[last_space_idx + 1:]\n",
    "            key = (y,x)\n",
    "            if x not in training_observations_x: \n",
    "                training_observations_x.append(x)\n",
    "            if y in y_count:\n",
    "                y_count[y] += 1\n",
    "            else:\n",
    "                y_count[y] = 1\n",
    "            if key in emission_count:\n",
    "                emission_count[key] += 1\n",
    "            else:\n",
    "                emission_count[key] = 1\n",
    "    return y_count, emission_count, training_observations_x\n",
    "\n",
    "def readDevIn(filePath):\n",
    "    x_sequences = []\n",
    "    current_sequence = []\n",
    "    with open(filePath, 'r') as file:\n",
    "        for line in file:\n",
    "            x = line.strip()\n",
    "            if not x:\n",
    "                if current_sequence: \n",
    "                    x_sequences.append(current_sequence)\n",
    "                    current_sequence = [] \n",
    "            else:\n",
    "                current_sequence.append(x)\n",
    "        if current_sequence:\n",
    "            x_sequences.append(current_sequence)\n",
    "    return x_sequences\n",
    "\n",
    "def write_seq_pairs_to_file(file_path, list_of_sequences):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for seq_pairs in list_of_sequences:\n",
    "            for x, y in seq_pairs:\n",
    "                 file.write(f\"{x} {y}\\n\")\n",
    "            file.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1a \n",
    "Write a function that estimates the emission parameters from the training set using MLE (maximum\n",
    "likelihood estimation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_parameters(x_t, y_t, y_count, emission_count):\n",
    "    return emission_count.get((y_t, x_t), 0) / y_count.get(y_t, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 1b\n",
    "One problem with estimating the emission parameters is that some words that appear in the test set\n",
    "do not appear in the training set. \n",
    "\n",
    "One simple idea to handle this issue is as follows. We introduce\n",
    "a special word token #UNK#, and make the following modifications to the computation of emission\n",
    "\n",
    "During the testing phase, if the word does not appear in the training set, we replace that word with\n",
    "#UNK#.\n",
    "Set k to 1, implement this fix into your function for computing the emission parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_parameters_updated(x_t,y_t,y_count,emmision_count,training_observations_x,k=1):\n",
    "    if(x_t in training_observations_x):\n",
    "        return emmision_count.get((y_t,x_t),0)/(y_count[y_t]+k)\n",
    "    else:\n",
    "        return k/(y_count[y_t]+k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1c\n",
    "Implement a simple sentiment analysis system that produces the tag\n",
    "yâˆ— = arg max y e(x|y) for each word x in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sentiment_analysis(x_seq, y_count, emission_count,training_observations_x):\n",
    "    Y = list(y_count.keys())\n",
    "    seq_pair = []\n",
    "    for x_s in x_seq:\n",
    "        max_y = None\n",
    "        max_emission_prob = 0\n",
    "        for y in Y:\n",
    "            emission_prob = emission_parameters_updated(x_s, y, y_count, emission_count,training_observations_x)\n",
    "            if emission_prob > max_emission_prob:\n",
    "                max_y = y\n",
    "                max_emission_prob = emission_prob\n",
    "        seq_pair.append((x_s, max_y))\n",
    "    return seq_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNwrite(readDevInPath, y_count, emission_count, training_observations_x, writeFilePath):\n",
    "    x_sequences = readDevIn(readDevInPath)\n",
    "    list_of_sequences = [] \n",
    "    for x_seq in x_sequences:\n",
    "        seq_pairs = simple_sentiment_analysis(x_seq, y_count, emission_count,training_observations_x)\n",
    "        list_of_sequences.append(seq_pairs)\n",
    "    write_seq_pairs_to_file(writeFilePath, list_of_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_count_RU, emission_count_RU, training_observations_x_RU = readFileEmissionParameters(\"./Data/RU/train\")\n",
    "predictNwrite(\"./Data/RU/dev.in\", y_count_RU, emission_count_RU, training_observations_x_RU, \"./Data/RU/dev.p1.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RU results:\n",
    "\n",
    "#Entity in gold data: 389 <br>\n",
    "#Entity in prediction: 1816<br>\n",
    "\n",
    "#Correct Entity : 266 <br>\n",
    "#Entity  precision: 0.1465<br>\n",
    "#Entity  recall: 0.6838<br>\n",
    "#Entity  F: 0.2413<br>\n",
    "\n",
    "#Correct Sentiment : 129<br>\n",
    "#Sentiment  precision: 0.0710<br>\n",
    "#Sentiment  recall: 0.3316<br>\n",
    "#Sentiment  F: 0.1170"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_count_ES, emission_count_ES, training_observations_x_ES = readFileEmissionParameters(\"./Data/ES/train\")\n",
    "predictNwrite(\"./Data/ES/dev.in\", y_count_ES, emission_count_ES, training_observations_x_ES, \"./Data/ES/dev.p1.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Entity in gold data: 229 <br>\n",
    "#Entity in prediction: 1466 <br>\n",
    "\n",
    "#Correct Entity : 178 <br>\n",
    "#Entity  precision: 0.1214 <br>\n",
    "#Entity  recall: 0.7773 <br>\n",
    "#Entity  F: 0.2100 <br>\n",
    "\n",
    "#Correct Sentiment : 97 <br>\n",
    "#Sentiment  precision: 0.0662 <br>\n",
    "#Sentiment  recall: 0.4236 <br>\n",
    "#Sentiment  F: 0.1145 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
